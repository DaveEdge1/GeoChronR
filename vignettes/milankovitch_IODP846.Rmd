---
title: "Search for Milankovitch"
output: html_notebook
---

## Introduction
In this notebook we hunt for Milankovitch cycles in the record of:

  - Mix, A. C., J. Le, and N. J. Shackleton (1995a), Benthic foraminiferal stable isotope stratigraphy from Site 846: 0–1.8 Ma, Proc. Ocean Drill. Program Sci. Results, 138, 839–847.
  - Shackleton, N. J. (1995), New data on the evolution of Pliocene climate variability, in Paleoclimate and Evolution, With Emphasis on Human Origins, edited by E. S. Vrba et al., pp. 242-248, Yale Univ. Press, New Haven, CT.

The data were aligned to the Benthic Stack of  [Lisiecki & Raymo (2005)](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2004PA001071) using the [HMM-Match](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2014PA002713) algorithm.  

First, load the data from `HMM_Alignment_8461.mat`. 
```{r}
#install.packages("R.matlab")
library(R.matlab)
library(ggplot2)
library(ggthemes)
library(astrochron)
path <- "/Users/julieneg/Documents/Science/Research/GeoChronR/spectral/data"
pathname <- file.path(path, "HMM_Alignment_8461_v6.mat")
iodp846 <- readMat(pathname)
probstack <- read.table("/Users/julieneg/Documents/Science/Research/GeoChronR/spectral/data/Prob_stack.txt", header = FALSE)
```

Let's plot it
```{r}
df = data.frame(t = iodp846$median.ali, d18O=iodp846$d18O, upper=iodp846$upper.95, lower=iodp846$lower.95,tens = iodp846$alignment)
ggplot(df) + geom_line(aes(x=t/1000,y=d18O),colour="orange") + ggtitle("IODP 846 aligment to ProbStack, central estimate") + ylab("d18O") + scale_x_continuous(breaks=seq(0,5)) + xlab("Age (Ma)") + scale_y_reverse() + theme_hc(base_size = 12, base_family = "sans", style = "darkunica", bgcolor = NULL)
```
Clearly there is a long-term trend here, paired with the transition from "41k world" to "100k world" somewhere around 0.8 Ma [Paillard, 2001]. 
To keep things simple and lower computational costs, let's focus on the last 1 Ma. Now, a standard assumption of spectral analysis is that data are evenly spaced in time. In real-world paleo timeseries this is seldom the case. Let's look at the distribution of time increments here: 

```{r}
dfs = dplyr::filter(df,t<=1000)
dt = diff(dfs$t)
ggplot() + xlim(c(0,10)) + 
  geom_histogram(aes(x=dt,y = ..density..), bins = 25, ,alpha = 0.8, fill = "orange") + ggtitle("Distribution of time intervals") + theme_hc(base_size = 12, base_family = "sans", style = "darkunica", bgcolor = NULL)
```

We see that over the past Ma, the time increments dt in this core are sharply peaked around 2.5 ka, but they range from 0 to about 7.5. For now, let us assume that the time axis, uneven though it is, is well-known (no uncertainty). 

## Time-certain spectral analysis 
There are two ways to proceed: 1) use methods that explictly deal with unevenly-spaced data, or 2) interpolate to a regular grid and apply standard methods. 
For 1, we could use the *Lomb-Scargle periodogram* or the lesser-known *nuspectral* package

### Lomb-Scargle periodogram
This is a very standard method implemented in many packages. For a review, see VanderPlas, J. T. (2018), Understanding the lomb–scargle periodogram, The Astrophysical Journal Supplement Series, 236(1), 16, doi:10.3847/1538-4365/aab766.

There are several ways to implement LS. GeoChronR does this via the [lomb](https://www.rdocumentation.org/packages/lomb) package:

```{r}
library(lomb)
spec.ls = lomb::lsp(dfs$d18O,times=dfs$t,ofac=1.1,plot = F)
# plot this 
p.ls <- ggplot() + geom_line(aes(x=spec.ls$scanned,y=spec.ls$power)) + xlab("Frequency (1/kyr)") + ylab("Normalized Power") +scale_x_log10() +scale_y_log10() + ggtitle("IODP 846 d18O, Lomb-Scargle periodogram")

# define function to annotate the spectrum (assumes log10 scaling)
plotSpectraAnnotate = function (p, periods = c(19,23,41,100)){
  #get the x- and y-axis ranges actually used in the graph
  ggp <- ggplot_build(p)
  ylims <- ggp$layout$panel_params[[1]]$y.range # this will break with multiplots... 
  for(per in periods){
    p <- p + annotate("segment", x = 1/per, xend = 1/per, y = 10**(ylims[1]-1), yend = 10**ylims[2],
    colour = "red", alpha = 0.5)
    p <- p +  annotate("text", x = 1.03*1/per, y = 2*10**ylims[2], label = format(per,digits=2, nsmall=0), colour = "red")
  }
return(p)  
}

p.ls <- plotSpectraAnnotate(p.ls)
show(p.ls)
```


Where it is clearly seen that the data appear to contain periodic signals at the Milankotich frequencies (and others). 

### Multi-taper Method
The Lomb-Scargle periodogram is a decent way to deal with unevenly-spaced timeseries, but it is still a periodogram, i.e. one of the worst estimators known to humankind. In particular, it is inconsistent: the variance of each estimate goes to infinity as the number of observations increases. A much better estimator is Thomson's Multi-Taper Method [Thomson, 1982], though the method currently only handles evenly-spaced data. Small potatoes! The data are not that far from evenly-spaced, so let's interpolate and see what we get. Conveniently, both the interpolation routine and mtm are available within the [astrochron](https://www.rdocumentation.org/packages/astrochron) package:

```{r}
library(astrochron)
dti = 2.5  # interpolation interval
dfe = linterp(dfs,dt=dti)
spec.mtm <- astrochron::mtm(dfe,padfac=1,ar1=TRUE,genplot = F,output=1, verbose = F, detrend=T)
sig.freq <- astrochron::mtm(dfe,padfac=1,ar1=TRUE,genplot = F,output=2, verbose = F, detrend=T)

# plot this 
p.mtm <- ggplot() + geom_line(aes(x=spec.mtm$Frequency,y=spec.mtm$Power)) + xlab("Frequency (1/kyr)") + ylab("Normalized Power") + scale_x_log10() +scale_y_log10() + ggtitle("IODP 846 d18O, Multi-taper method")
p.mtm <- plotSpectraAnnotate(p.mtm,periods = 1/sig.freq)
show(p.mtm)
```

We notice a few differences to the Lomb-Scargle periodogram. First, the high frequency part is much smoother, getting rid of a lot of high-frequency noise. This reveals strong power law behavior (linear decrease in these log units) from periods of 5 to 100 ky. *Astrochron* implements several tests to detect harmonic (sinusoidal) components. Like all tests, they are heavily dependent on a null hypothesis. The plain vanilla *astrochron::mtm()* assumes that we test against an AR(1) model. Using the option `output = 2` will export the frequencies identified as "significant" by this procedure. In this case, it identifies 41 and 19 ky (as it should), 90 ky (close enough to 100ky given the resolution), but surprisingly favors 55ky over the known 23ky precessional peak. Here it's helpful to take a step back and contemplate our null hypothesis. If we assume that the continuum of climate variability [Huybers & Curry, 2006] is well described by a power-law, maybe that is a better null. Never fear! astrochron has an app for that:

```{r}
spec.mtmPL <- astrochron::mtmPL(dfe,padfac=2,genplot = F,output=1, verbose = F, flow=fl, fhigh=fh)
sig.freqPL <- astrochron::mtmPL(dfe,padfac=2,genplot = F,output=2, verbose = F, flow=fl, fhigh=fh)

# plot this 
p.mtmPL <- ggplot() + geom_line(aes(x=spec.mtmPL$Frequency,y=spec.mtmPL$Power)) + xlab("Frequency (1/kyr)") + ylab("Normalized Power") + scale_x_log10() +scale_y_log10() + ggtitle("IODP 846 d18O, Multi-taper method, power-law null")
p.mtmPL <- plotSpectraAnnotate(p.mtmPL,periods = 1/sig.freqPL)
show(p.mtmPL)
```

This gets rid of the 55 kyr cycle, and now we've got the split precessional peak, consistent with the astronomical forcing [Berger, 1978]. Here we defined `fhigh = 0.1` as the highest frequency at which to see cycles. Tweak it to see what happens when you use a higher one. 


## Time-uncertain spectral analysis 
Now let's consider age uncertainties thanks to the [tuts package](https://www.rdocumentation.org/packages/tuts), which is designed to handle Gaussian uncertainties in the time assigned with each depth in a core. 

In our original dataframe (`df`), `median_ali` is the median age and `lower_95/upper_95` delineate the 95% confidence interval obtained from the HMM_match procedure.  Let us inspect the age uncertainties:

```{r}
df = data.frame(t = iodp846$median.ali, upper = iodp846$upper.95, lower=iodp846$lower.95)
library(ggplot2)
library(ggthemes)
ggplot(df) + geom_ribbon(aes(x=t/1000,ymin=lower-t,ymax=upper-t),fill="orange") + ggtitle("IODP 846 aligment to ProbStack, 95% CI width") + ylab("CI width (ky)") + scale_x_continuous(breaks=seq(0,5)) + xlab("Age (Ma)") + theme_hc(base_size = 12, base_family = "sans", style = "darkunica", bgcolor = NULL)
```

While they are not exactly Gaussian, they are not far from it over the past 1 Ma, which means the time-uncertainty model can be applied with too much hand-wringing:

```{r}
age_uncert = dfs$upper-dfs$lower
ggplot() + 
  geom_histogram(aes(x=age_uncert,y = ..density..), bins=10 , alpha = 0.9, fill = "orange") + ggtitle("Distribution of age uncertainties") + theme_hc(base_size = 12, base_family = "sans", style = "darkunica", bgcolor = NULL)
```

### GeoChronR Ensemble Strategy
As you can tell by now, the GeoChronR approach to uncertanty quantification and propagation is to leverage the power of ensembles. Here we will illustrate this with MTM. 
the HMM_match output for IODP846 comes with 1,000 realizations of the age model. Let us repeat the previous analysis by looping over those: 
```{r}
pf = 2 # padding factor
fl = 0.005
fh = 0.1
nens = 1000
values = dfs$d18O
time = dfs$tens.1
#  apply workflow to first member
dfe = linterp(data.frame(time,values),dt=dti,genplot=F,check=F,verbose=F)  # define local dataframe
mtmPL.main    <- astrochron::mtmPL(dfe,padfac=2,genplot = F,output=1, verbose = F, flow=fl, fhigh=fh)
mtmPL.sigfreq <- astrochron::mtmPL(dfe,padfac=2,genplot = F,output=2, verbose = F, flow=fl, fhigh=fh)
# define output matrices
ens.mtmPL.power   <-  matrix(NA,ncol=nens,nrow=length(mtmPL.main$Frequency))
ens.mtmPL.sigfreq <-  matrix(0,ncol=nens,nrow=length(mtmPL.main$Frequency))
# store output for first member
ens.mtmPL.power[,1] <-mtmPL.main$Power
ens.mtmPL.sigfreq[match(mtmPL.sigfreq$Frequency, mtmPL.main$Frequency, nomatch = 0),1] <- 1

pb = txtProgressBar(min=2,max = nens,style = 3)
# rinse, repeat
for (k in 2:nens){ 
  time = dfs[,k+4]
  dfe = linterp(data.frame(time,values),dt=dti,genplot=F,check=F,verbose=F)  # define local dataframe
  mtmPL.main <- astrochron::mtmPL(dfe,padfac=pf,genplot = F,output=1, verbose = F, flow=fl, fhigh=fh)
  mtmPL.sigfreq <- astrochron::mtmPL(dfe,padfac=pf,genplot = F,output=2, verbose = F, flow=fl, fhigh=fh)
  ens.mtmPL.power[,k] = mtmPL.main$Power
  ens.mtmPL.sigfreq[match(mtmPL.sigfreq$Frequency, mtmPL.main$Frequency, nomatch = 0),k]=1
}
freqs.prob = rowMeans(ens.mtmPL.sigfreq)
f = mtmPL.main$Frequency
spec.ens = list(freqs = matrix(f,nrow=length(f),ncol=nens,byrow=F), power = ens.mtmPL.power, powerSyn = NA, prob = freqs.prob)
# let's select frequencies for plotting
highlight.freqs = f[freqs.prob>.5]
highlight.probs = freqs.prob[freqs.prob>.5]
# plot it
specPlot <- ggplot() + scale_alpha_continuous(range = c(0.4,.8)) + geom_vline(xintercept = highlight.freqs,colour = "red",alpha=highlight.probs, size = 2)
period = c(10,20,50,100,200)
# basic pattern: 10   20   50, then repeat
specPlot <- specPlot + xlab("Period (ka)") + ylab("Normalized Spectral Density") + scale_x_log10(labels = as.character(period),breaks = 1/period) + scale_y_log10() + ggtitle("IODP 846 d18O, MTM with 1,000 age models")
#specPlot <- plotSpectraAnnotate(specPlot) +

specPlot <- plotTimeseriesEnsRibbons(spec.ens$freqs,spec.ens$power,add.to.plot = specPlot)

show(specPlot)

# need to snatch units from LiPD file
# label periods 
# find closest
#period10Max = ceiling((max(time) - min(time))/10)*10 # longest period
#period10Min = floor(1/max(freqs)/10)*10
#library(pracma)
#period = logspace(log10(periodMin),log10(periodMax),7) # not 


#specPlot <- specPlot + scale_x_continuous(labels = as.character(period),breaks = 1/period) # label periods
```


Now let's do this with GeoChronR. 

```{r}
time = iodp846$alignment[1:382,]
values = dfs$d18O
mtm.ens.spec = computeSpectraEns(values, time,method = 'mtm')
```



pretty plot [(credit)](https://stackoverflow.com/questions/37326686/ggplot2-geom-ribbon-with-alpha-dependent-on-data-density-along-y-axis-for-each)

# you'll need to set alpha=sort(group) in the geom_ribbon call, as otherwise it thinks group 59 is next quantile from 591

```{r}
library(splines)
library(quantreg)
library(reshape2)
library(dplyr)


#Set quantiles for density ribbons:
nq = 50 # Numbre of quantiles
qq = seq(0,1, length.out=nq)
#Run the quantile regression for each quantile. We use a flexible spline function to get a good fit to the sine function:
m1 = rq(y ~ ns(x,10), data=sim.df, tau=qq)
Create data frame for use by geom_ribbon to plot density quantiles.

Create a data frame of regression quantile predictions using predict:

xvals = seq(min(sim.df$x), max(sim.df$x), length.out=100)
rqs = data.frame(x=xvals, predict(m1, newdata=data.frame(x=xvals)))
names(rqs) = c("x", paste0("p",100*qq))
Reshape the data so that the predictions for each quantile serve as the ymax for one quantile and the ymin for the next quantile in succession (with the exception that the first quantile serves only once as the first ymin and the last quantile serves only once as the last ymax). Put the data in long format so that we can group by quantile in ggplot:
dat1 = rqs[, -length(rqs)]
names(dat1)[-1] = paste0(names(dat1)[-1])
dat2 = rqs[, -2]
names(dat2)[-1] = paste0(names(dat1)[-1])

```
```{r}
x = 
   ns(x,10)
```



### Bayesian Frequency Selection
Let us prepare this dataset for analysis w/ TUTS Bayesian Frequency Selection.
One thing to be aware of is that the core top has zero uncertainty, but TUTS requires finite (non-zero) uncertainties. We thus need to give it a small, but nonzero, value (100y, say).

```{r}
library(tuts)
y <- dfs$d18O
ti.mu <-  dfs$t #assume the median and the mean coincide
# extract standard deviation. Assume that the width of the 95% intervals is 2*1.96 * \sigma
ti.sd <- (age_uncert)/3.92
ti.sd[ti.sd<0.1]=0.1 # replace zero value so it doesn't break BFS
```

We are now ready to run TUTS. Now, running out a Monte Carlo Markov chain on this many frequencies might very well break your computer. So let's first run their version of the Lomb-Scargle periodogram to identify

```{r}
TULS=tuls(y=y,ti.mu=ti.mu,ti.sd=ti.sd,n.sim=500)
candidate.frequencies = summary(TULS)
```

```{r}
BFS = tubfs(y=y,ti.mu=ti.mu,ti.sd=ti.sd,n.sim=10,freqs=25)
```
Wow, that only took 12h!

```{r}
plot(BFS,type='periodogram')               # spectral analysis (CI, burn).
plot(BFS,type='predTUTS', CI=0.99)         # One step predictions (CI, burn).
plot(BFS,type='cv')                        # 5 fold cross validation plot (CI, burn).
plot(BFS,type='GR')                        # Gelman-Rubin diagnostics (CI, burn).
plot(BFS,type='mcmc')                      # mcmc diagnostics.
plot(BFS,type='volatility')                # Volatility realizaitons.
```
This is going nowhere. 



#WRAP=tuwrap(y=y,ti.mu=ti.mu,ti.sd=ti.sd,n.sim=100,CV=FALSE) 








<!-- Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by -->
<!-- pressing *Cmd+Option+I*. -->
<!-- When you save the notebook, an HTML file containing the code and output will be -->
<!-- saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview -->
<!-- the HTML file). -->
<!-- The preview shows you a rendered HTML copy of the contents of the editor. -->
<!-- Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, -->
<!-- the output of the chunk when it was last run in the editor is displayed. -->

